{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT- Aspect Category.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bCB5i38-W3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "191cb0f9-a194-453f-9013-82b7f072decf"
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.5.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.13.23)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.23 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.16.23)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.23->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.23->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.23->boto3->pytorch_pretrained_bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CHIPWSrCQAvs",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import string \n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Precision, Recall, FalseNegatives, FalsePositives\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from tensorflow.keras.models import Model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHArMTeM82Jj",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50D_wAeU82Jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import data\n",
        "train = pd.read_excel('Trainset.xlsx')\n",
        "test = pd.read_excel('Testset.xlsx')\n",
        "\n",
        "# Eliminate the NAs\n",
        "train = train.fillna('')\n",
        "test = test.fillna('')\n",
        "\n",
        "# Remove the rows without Opinion Category values\n",
        "train = train[train.OpinionCategory != ''] \n",
        "test = test[test.OpinionCategory != ''] \n",
        "\n",
        "# Sort the data\n",
        "train = train.sort_values('Sentence_ID').reset_index(drop=True)\n",
        "test = test.sort_values('Sentence_ID').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niBCCvXK82Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "4a7a89f6-8350-45d5-9ce4-4e68e850fce7"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_number</th>\n",
              "      <th>Review_ID</th>\n",
              "      <th>ID_and_Review</th>\n",
              "      <th>OutOfScope</th>\n",
              "      <th>Sentence_ID</th>\n",
              "      <th>OpinionCategory</th>\n",
              "      <th>OpinionFrom</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>AspectTerm</th>\n",
              "      <th>OpinionTo</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1004293</td>\n",
              "      <td>1</td>\n",
              "      <td>1004293:0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>RESTAURANT#GENERAL</td>\n",
              "      <td>51</td>\n",
              "      <td>negative</td>\n",
              "      <td>place</td>\n",
              "      <td>56</td>\n",
              "      <td>Judging from previous posts this used to be a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1004293</td>\n",
              "      <td>1</td>\n",
              "      <td>1004293:1</td>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>75</td>\n",
              "      <td>negative</td>\n",
              "      <td>staff</td>\n",
              "      <td>80</td>\n",
              "      <td>We, there were four of us, arrived at noon - t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004293</td>\n",
              "      <td>1</td>\n",
              "      <td>1004293:2</td>\n",
              "      <td></td>\n",
              "      <td>3</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>They never brought us complimentary noodles, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004293</td>\n",
              "      <td>1</td>\n",
              "      <td>1004293:3</td>\n",
              "      <td></td>\n",
              "      <td>4</td>\n",
              "      <td>FOOD#QUALITY</td>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>food</td>\n",
              "      <td>8</td>\n",
              "      <td>The food was lousy - too sweet or too salty an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1004293</td>\n",
              "      <td>1</td>\n",
              "      <td>1004293:3</td>\n",
              "      <td></td>\n",
              "      <td>4</td>\n",
              "      <td>FOOD#STYLE_OPTIONS</td>\n",
              "      <td>52</td>\n",
              "      <td>negative</td>\n",
              "      <td>portions</td>\n",
              "      <td>60</td>\n",
              "      <td>The food was lousy - too sweet or too salty an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ID_number  ...                                               Text\n",
              "0   1004293  ...  Judging from previous posts this used to be a ...\n",
              "1   1004293  ...  We, there were four of us, arrived at noon - t...\n",
              "2   1004293  ...  They never brought us complimentary noodles, i...\n",
              "3   1004293  ...  The food was lousy - too sweet or too salty an...\n",
              "4   1004293  ...  The food was lousy - too sweet or too salty an...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qotxytg82J0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b0ee8e8-e20c-4d53-fc9f-2f68351da518"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2507, 11), (859, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F04uJQJN82J5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "771d8af8-5034-46c7-a05c-50fff04cdfcd"
      },
      "source": [
        "train.OpinionCategory.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FOOD#QUALITY                849\n",
              "SERVICE#GENERAL             449\n",
              "RESTAURANT#GENERAL          422\n",
              "AMBIENCE#GENERAL            255\n",
              "FOOD#STYLE_OPTIONS          137\n",
              "RESTAURANT#MISCELLANEOUS     98\n",
              "FOOD#PRICES                  90\n",
              "RESTAURANT#PRICES            80\n",
              "DRINKS#QUALITY               47\n",
              "DRINKS#STYLE_OPTIONS         32\n",
              "LOCATION#GENERAL             28\n",
              "DRINKS#PRICES                20\n",
              "Name: OpinionCategory, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9cbA5_C82J8",
        "colab_type": "text"
      },
      "source": [
        "Train data consists of 11 variables. The four of them indicate the ID numbers of the sentences, the reviewer, the review and the combination of them. OutofScope variable loses its function when I eliminated the null OpinionCategory values. The Opinion Category shows the aspect which the review refers to. The Opinion Category consists of 12 classes and each class has an entity and a corresponding attribute, in other words, E#A pairs. \n",
        "\n",
        "In this notebook, I will deal only with the Opinion Category and the corresponding reviews under the Text column and leave the analysis for Polarity and AspectTerm (and related columns with AspectTerm) to other notebooks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c-Lo-YjuQAwM",
        "outputId": "02b5571f-a072-4c3c-86f7-6de7decc03cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Since the opinion category consists of categories, they needed to be one-hot encoded for the model.\n",
        "train.OpinionCategory = train.OpinionCategory.astype('category')\n",
        "one_hot = to_categorical(train.OpinionCategory.cat.codes)\n",
        "one_hot = pd.DataFrame(one_hot)\n",
        "\n",
        "test.OpinionCategory = test.OpinionCategory.astype('category')\n",
        "one_hot_test = to_categorical(test.OpinionCategory.cat.codes)\n",
        "one_hot_test = pd.DataFrame(one_hot_test)\n",
        "\n",
        "one_hot.shape, one_hot_test.shape # There are 12 opinion category classes."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2507, 12), (859, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "olkeXSoZQAwU",
        "colab": {}
      },
      "source": [
        "# As mentioned above, for the analysis only three columns are necessary.\n",
        "useful_train = train[['Sentence_ID','OpinionCategory','Text']]\n",
        "useful_test = test[['Sentence_ID','OpinionCategory','Text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHupRIao82KC",
        "colab_type": "text"
      },
      "source": [
        "## Multilabeling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6yHRl0W82KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, concatenate the train data and the one-hot-encoding of the opinion category classes.\n",
        "data_train = pd.concat([useful_train, one_hot], axis=1)\n",
        "data_test = pd.concat([useful_test, one_hot_test], axis=1)\n",
        "\n",
        "# Since the reviewer may have mentioned more than one opinion in a sentence, \n",
        "# I sum the one-hot-encoded classes of each sentence.\n",
        "multi_label = data_train.groupby('Sentence_ID').sum().reset_index(drop=True)\n",
        "multi_label_test = data_test.groupby('Sentence_ID').sum().reset_index(drop=True)\n",
        "\n",
        "# In each sentence, an opinion category may be refered more than one.\n",
        "# Because of that, there were values besides 0 and 1, after the summation.\n",
        "# Since being refered is important rather than how many times, the values such as 2 or 3 are reverted to one.\n",
        "multi_label = np.array(multi_label.astype(bool).astype(int))\n",
        "multi_label_test = np.array(multi_label_test.astype(bool).astype(int))\n",
        "\n",
        "# After the multi-labeling of the sentences, remove the duplicates.\n",
        "train_Text = data_train.drop_duplicates(subset=['Sentence_ID'], keep='last').Text\n",
        "test_Text = data_test.drop_duplicates(subset=['Sentence_ID'], keep='last').Text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vcU9Oz7NQAwe",
        "outputId": "e21fde82-23e6-4b40-bc2b-22e45ae12ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "multi_label, multi_label.shape, multi_label_test, multi_label_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 1],\n",
              "        [0, 0, 0, ..., 0, 0, 1],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 1],\n",
              "        [0, 0, 0, ..., 0, 0, 1],\n",
              "        [0, 0, 0, ..., 0, 0, 1]]), (1708, 12), array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 1, 0, 1],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]), (587, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7jT5XH882KI",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing for the BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GzluFLFkQAwu",
        "outputId": "f74d527b-5584-425d-a5a8-2516f7357e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# add special tokens for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sent + \" [SEP]\" for sent in train_Text.astype(str)]\n",
        "sentences_test = [\"[CLS] \" + sent + \" [SEP]\" for sent in test_Text.astype(str)]\n",
        "\n",
        "sentences[0], sentences_test[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS] Judging from previous posts this used to be a good place, but not any longer. [SEP]',\n",
              " '[CLS] Yum! [SEP]')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2zHTKXm82KK",
        "colab_type": "text"
      },
      "source": [
        "For the tokenization, pre-trained Bert-Base-Uncased dictionary is used. They constructed it with WordPiece embeddings with a 30,000 token vocabulary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B-3Al2iXQAww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6402cf9d-3b30-4fc5-afe2-9c77a9017301"
      },
      "source": [
        "# Tokenize with BERT tokenizer both train and test data\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "tokenized_texts_test = [tokenizer.tokenize(sent) for sent in sentences_test]\n",
        "\n",
        "tokenized_texts[0], tokenized_texts_test[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['[CLS]',\n",
              "  'judging',\n",
              "  'from',\n",
              "  'previous',\n",
              "  'posts',\n",
              "  'this',\n",
              "  'used',\n",
              "  'to',\n",
              "  'be',\n",
              "  'a',\n",
              "  'good',\n",
              "  'place',\n",
              "  ',',\n",
              "  'but',\n",
              "  'not',\n",
              "  'any',\n",
              "  'longer',\n",
              "  '.',\n",
              "  '[SEP]'],\n",
              " ['[CLS]', 'yu', '##m', '!', '[SEP]'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_nQt7PY82KM",
        "colab_type": "text"
      },
      "source": [
        "For the BERT model to work, we need three inputs. \n",
        "- Input IDs: shows the ID number of each token with padding. The ID numbers are restored from the BERT vocabulary dictionary.\n",
        "- Mask IDs: indicates which elements in the sequence are tokens and which are padding elements.\n",
        "- Segment IDs: distinguishes different sentences, 0 for one-sentence sequence, 1 if there are two sentences.\n",
        "\n",
        "The functions below are extracted from: https://towardsdatascience.com/simple-bert-using-tensorflow-2-0-132cb19e9b22"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RNCcS863QAwx",
        "colab": {}
      },
      "source": [
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    if len(tokens) > max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85JdLD8582KO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a025714-4807-40dd-98a9-65ac3965d39e"
      },
      "source": [
        "# find the longest sequence for the padding\n",
        "def find_max_list(list):\n",
        "    list_len = [len(i) for i in list]\n",
        "    return max(list_len)\n",
        "    \n",
        "longestSeq_train = find_max_list(tokenized_texts)\n",
        "longestSeq_test = find_max_list(tokenized_texts_test)\n",
        "max_seq_length = max(longestSeq_train, longestSeq_test)\n",
        "print(max_seq_length)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IkIZ39cpQAwy",
        "colab": {}
      },
      "source": [
        "# Find input_ids, mask_ids and segment_ids of the train and test data.\n",
        "max_seq_length = max_seq_length\n",
        "input_ids = []\n",
        "for i in range(len(tokenized_texts)):\n",
        "    input_ids.append(get_ids(tokenized_texts[i], tokenizer, max_seq_length))\n",
        "\n",
        "mask_ids = [] \n",
        "for i in range(len(tokenized_texts)):\n",
        "    mask_ids.append(get_masks(tokenized_texts[i], max_seq_length))\n",
        "    \n",
        "segments_ids = [] \n",
        "for i in range(len(tokenized_texts)):\n",
        "    segments_ids.append(get_segments(tokenized_texts[i], max_seq_length))\n",
        "    \n",
        "input_ids_test = []\n",
        "for i in range(len(tokenized_texts_test)):\n",
        "    input_ids_test.append(get_ids(tokenized_texts_test[i], tokenizer, max_seq_length))\n",
        "\n",
        "mask_ids_test = [] \n",
        "for i in range(len(tokenized_texts_test)):\n",
        "    mask_ids_test.append(get_masks(tokenized_texts_test[i], max_seq_length))\n",
        "    \n",
        "segments_ids_test = [] \n",
        "for i in range(len(tokenized_texts_test)):\n",
        "    segments_ids_test.append(get_segments(tokenized_texts_test[i], max_seq_length))\n",
        "    \n",
        "# For the model, I converted the lists to tensors.\n",
        "input_ids = tf.convert_to_tensor(input_ids, dtype = tf.int32)\n",
        "mask_ids = tf.convert_to_tensor(mask_ids, dtype = tf.int32)\n",
        "segments_ids = tf.convert_to_tensor(segments_ids, dtype = tf.int32)\n",
        "\n",
        "input_ids_test = tf.convert_to_tensor(input_ids_test, dtype = tf.int32)\n",
        "mask_ids_test = tf.convert_to_tensor(mask_ids_test, dtype = tf.int32)\n",
        "segments_ids_test = tf.convert_to_tensor(segments_ids_test, dtype = tf.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiuTf_Bo82KR",
        "colab_type": "text"
      },
      "source": [
        "# The BERT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKCLX9e182KR",
        "colab_type": "text"
      },
      "source": [
        "I used the uncased BERT model with 12 hidden layers and 110M parameters, trained on Wikipedia and Book-Corpus data and hosted by Google on TensorFlow Hub. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9bpAlyu82KR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3727c6b2-3029-41eb-da04-33a5197fa0b6"
      },
      "source": [
        "random.seed(123)\n",
        "# Three Inputs of the Bert Model\n",
        "InputIDLayer = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"InputIDs\")\n",
        "MaskIDLayer = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"MaskIDs\")\n",
        "SegmentIDLayer = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"SegmentIDs\")\n",
        "\n",
        "# Import the pre-trained uncased Bert model\n",
        "bertLayer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=True)\n",
        "\n",
        "# Since it is a classisfication problem, the pooled output is needed.\n",
        "pooled_output, sequence_output = bertLayer([InputIDLayer, MaskIDLayer, SegmentIDLayer])\n",
        "pooled_output = Dropout(0.5)(pooled_output)\n",
        "output = Dense(units = 768, activation = \"tanh\")(pooled_output)\n",
        "output = Dropout(0.5)(output)\n",
        "output = Dense(units = 12, activation = \"softmax\")(output)\n",
        "\n",
        "model = Model(inputs=[InputIDLayer, MaskIDLayer, SegmentIDLayer], outputs = output)\n",
        "\n",
        "# Model Compilation\n",
        "learning_rate = 2e-5\n",
        "number_of_epochs = 10\n",
        "optimizer = Adam(learning_rate = learning_rate, epsilon = 1e-08)\n",
        "loss = CategoricalCrossentropy(from_logits = False)\n",
        "metrics = [Precision(), Recall(),\n",
        "          FalseNegatives(), FalsePositives()]\n",
        "\n",
        "model.compile(optimizer = optimizer, \n",
        "              loss = loss,\n",
        "              metrics = metrics)\n",
        "\n",
        "# Model Training & Fine-Tuning on train data\n",
        "earlyStopping = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 1)\n",
        "\n",
        "bert_history = model.fit([input_ids, mask_ids, segments_ids], [multi_label],\n",
        "                         epochs = number_of_epochs, \n",
        "                         batch_size = 64,\n",
        "                         validation_split = 0.1,\n",
        "                         callbacks = [earlyStopping]\n",
        "                         )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 51s 2s/step - loss: 3.2709 - precision: 0.3822 - recall: 0.0295 - false_negatives: 1976.0000 - false_positives: 97.0000 - val_loss: 2.5494 - val_precision: 1.0000 - val_recall: 0.0090 - val_false_negatives: 220.0000 - val_false_positives: 0.0000e+00\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 49s 2s/step - loss: 2.8982 - precision: 0.4213 - recall: 0.0894 - false_negatives: 1854.0000 - false_positives: 250.0000 - val_loss: 2.4071 - val_precision: 0.6620 - val_recall: 0.2117 - val_false_negatives: 175.0000 - val_false_positives: 24.0000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 49s 2s/step - loss: 2.6552 - precision: 0.6920 - recall: 0.2284 - false_negatives: 1571.0000 - false_positives: 207.0000 - val_loss: 2.0084 - val_precision: 0.8533 - val_recall: 0.2883 - val_false_negatives: 158.0000 - val_false_positives: 11.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 49s 2s/step - loss: 2.2535 - precision: 0.8428 - recall: 0.4136 - false_negatives: 1194.0000 - false_positives: 157.0000 - val_loss: 1.8841 - val_precision: 0.8435 - val_recall: 0.5586 - val_false_negatives: 98.0000 - val_false_positives: 23.0000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 49s 2s/step - loss: 2.0498 - precision: 0.8718 - recall: 0.4641 - false_negatives: 1091.0000 - false_positives: 139.0000 - val_loss: 1.7432 - val_precision: 0.8873 - val_recall: 0.5676 - val_false_negatives: 96.0000 - val_false_positives: 16.0000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 49s 2s/step - loss: 1.7658 - precision: 0.9081 - recall: 0.5629 - false_negatives: 890.0000 - false_positives: 116.0000 - val_loss: 1.7803 - val_precision: 0.8784 - val_recall: 0.5856 - val_false_negatives: 92.0000 - val_false_positives: 18.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ag-7pkI82KT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "4c9ea950-cbd3-40be-9843-14d94782d241"
      },
      "source": [
        "# Model Evaluation - Loss, Precision, Recall, PrecisionAtRecall, RecallAtPrecision, FalseNegatives, FalsePositives\n",
        "results = model.evaluate([input_ids_test, mask_ids_test, segments_ids_test], multi_label_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 7s 390ms/step - loss: 1.8160 - precision: 0.8510 - recall: 0.5841 - false_negatives: 309.0000 - false_positives: 76.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBLwoIQaUELY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b01363cc-7b03-469c-a793-a047d65711a9"
      },
      "source": [
        "f1_score = 2 * (results[1] * results[2])/(results[1] + results[2])\n",
        "f1_score"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.692737424027747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6xWVtGDiFFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d2e3ab96-c280-44f7-dabb-0fadd64d9aab"
      },
      "source": [
        "# Dataframe for f1 scores:\n",
        "BERT_models = {'Optimizers': ['Adam','Adam','SGD','SGD'],\n",
        "        'DenseLayers': ['with', 'without', 'with', 'without'],\n",
        "        'F1Scores': [f1_score,f1_score2,f1_score3,f1_score4]}\n",
        "\n",
        "BERT_models = pd.DataFrame(BERT_models, columns = ['Optimizers', 'DenseLayers', 'F1Scores' ])\n",
        "print(BERT_models)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Optimizers DenseLayers  F1Scores\n",
            "0       Adam        with  0.692737\n",
            "1       Adam     without  0.711599\n",
            "2        SGD        with  0.731745\n",
            "3        SGD     without  0.722611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuJueYWRjk7o",
        "colab_type": "text"
      },
      "source": [
        "As can be seen above, the BERT model with SGD optimizer with extra dense layers gives the best result, with f1 score 0.73."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyPclCfC82KW",
        "colab_type": "text"
      },
      "source": [
        "## Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdZv5OL-82KW",
        "colab_type": "text"
      },
      "source": [
        "I would like to compare the changes on BERT model under the Appendix to compare with the main model.\n",
        "- Main model without extra Dense layers\n",
        "- SGD optimizer (vs. Adam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ebYtA4x82KW",
        "colab_type": "text"
      },
      "source": [
        "### Without extra Dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNu-vu4B82KW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cee1bec-356a-408f-9815-415857507b60"
      },
      "source": [
        "random.seed(123)\n",
        "# Three Inputs of the Bert Model\n",
        "InputIDLayer2 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"InputIDs\")\n",
        "MaskIDLayer2 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"MaskIDs\")\n",
        "SegmentIDLayer2 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"SegmentIDs\")\n",
        "\n",
        "# Import the pre-trained uncased Bert model\n",
        "bertLayer2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=True)\n",
        "\n",
        "# Since it is a classisfication problem, the pooled output is needed.\n",
        "pooled_output2, sequence_output2 = bertLayer2([InputIDLayer2, MaskIDLayer2, SegmentIDLayer2])\n",
        "output2 = Dense(12, activation = 'softmax')(pooled_output2)\n",
        "\n",
        "model2 = Model(inputs=[InputIDLayer2, MaskIDLayer2, SegmentIDLayer2], outputs = output2)\n",
        "\n",
        "# Model Compilation\n",
        "learning_rate = 2e-5\n",
        "number_of_epochs = 10\n",
        "optimizer2 = Adam(learning_rate = learning_rate, epsilon = 1e-08)\n",
        "loss2 = CategoricalCrossentropy(from_logits = False)\n",
        "metrics2 = [Precision(), Recall(),\n",
        "          FalseNegatives(), FalsePositives()]\n",
        "\n",
        "model2.compile(optimizer = optimizer2, \n",
        "              loss = loss2,\n",
        "              metrics = metrics2)\n",
        "\n",
        "# Model Training & Fine-Tuning on train data\n",
        "earlyStopping2 = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 1)\n",
        "\n",
        "bert_history2 = model2.fit([input_ids, mask_ids, segments_ids], [multi_label],\n",
        "                         epochs = number_of_epochs, \n",
        "                         batch_size = 64,\n",
        "                         validation_split = 0.1,\n",
        "                         callbacks = [earlyStopping2]\n",
        "                         )\n",
        "# Model Evaluation - Loss, Precision, Recall, PrecisionAtRecall, RecallAtPrecision, FalseNegatives, FalsePositives\n",
        "results2 = model2.evaluate([input_ids_test, mask_ids_test, segments_ids_test], multi_label_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 50s 2s/step - loss: 2.6635 - precision: 0.8504 - recall: 0.2004 - false_negatives: 2222.0000 - false_positives: 98.0000 - val_loss: 2.0305 - val_precision: 0.7766 - val_recall: 0.3288 - val_false_negatives: 149.0000 - val_false_positives: 21.0000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 49s 2s/step - loss: 1.8947 - precision: 0.8464 - recall: 0.5250 - false_negatives: 967.0000 - false_positives: 194.0000 - val_loss: 1.5111 - val_precision: 0.9313 - val_recall: 0.5495 - val_false_negatives: 100.0000 - val_false_positives: 9.0000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 49s 2s/step - loss: 1.4595 - precision: 0.9204 - recall: 0.5791 - false_negatives: 857.0000 - false_positives: 102.0000 - val_loss: 1.4602 - val_precision: 0.9416 - val_recall: 0.5811 - val_false_negatives: 93.0000 - val_false_positives: 8.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 48s 2s/step - loss: 1.2436 - precision: 0.9558 - recall: 0.6478 - false_negatives: 717.0000 - false_positives: 61.0000 - val_loss: 1.5648 - val_precision: 0.8986 - val_recall: 0.5991 - val_false_negatives: 89.0000 - val_false_positives: 15.0000\n",
            "19/19 [==============================] - 8s 398ms/step - loss: 1.6063 - precision: 0.8518 - recall: 0.6110 - false_negatives: 289.0000 - false_positives: 79.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdWnn-WnVCWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de1f46e8-b500-4a60-841e-35d03603eb93"
      },
      "source": [
        "f1_score2 = 2 * (results2[1] * results2[2])/(results2[1] + results2[2])\n",
        "f1_score2 "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7115987665154876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7tO6gxw82Ka",
        "colab_type": "text"
      },
      "source": [
        "### With SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZNrZSNO82Kb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f53bf5a-f3d0-4b19-c74a-337bdb2e5857"
      },
      "source": [
        "random.seed(123)\n",
        "# Three Inputs of the Bert Model\n",
        "InputIDLayer3 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"InputIDs\")\n",
        "MaskIDLayer3 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"MaskIDs\")\n",
        "SegmentIDLayer3 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"SegmentIDs\")\n",
        "\n",
        "# Import the pre-trained uncased Bert model\n",
        "bertLayer3 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=True)\n",
        "\n",
        "# Since it is a classisfication problem, the pooled output is needed.\n",
        "pooled_output3, sequence_output3 = bertLayer3([InputIDLayer3, MaskIDLayer3, SegmentIDLayer3])\n",
        "pooled_output3 = Dropout(0.5)(pooled_output3)\n",
        "output3 = Dense(units = 768, activation = \"tanh\")(pooled_output3)\n",
        "output3 = Dropout(0.5)(output3)\n",
        "output3 = Dense(units = 12, activation = \"softmax\")(output3)\n",
        "\n",
        "model3 = Model(inputs=[InputIDLayer3, MaskIDLayer3, SegmentIDLayer3], outputs = output3)\n",
        "\n",
        "# Model Compilation\n",
        "learning_rate = 0.01\n",
        "number_of_epochs = 10\n",
        "optimizer3 = SGD(learning_rate = learning_rate)\n",
        "loss3 = CategoricalCrossentropy(from_logits = False)\n",
        "metrics3 = [Precision(), Recall(),\n",
        "          FalseNegatives(), FalsePositives()]\n",
        "\n",
        "model3.compile(optimizer = optimizer3, \n",
        "              loss = loss3,\n",
        "              metrics = metrics3)\n",
        "\n",
        "# Model Training & Fine-Tuning on train data\n",
        "earlyStopping3 = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 1)\n",
        "\n",
        "bert_history3 = model3.fit([input_ids, mask_ids, segments_ids], [multi_label],\n",
        "                         epochs = number_of_epochs, \n",
        "                         batch_size = 32,\n",
        "                         validation_split = 0.1,\n",
        "                         callbacks = [earlyStopping3]\n",
        "                         )\n",
        "# Model Evaluation - Loss, Precision, Recall, PrecisionAtRecall, RecallAtPrecision, FalseNegatives, FalsePositives\n",
        "results3 = model3.evaluate([input_ids_test, mask_ids_test, segments_ids_test], multi_label_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 55s 1s/step - loss: 2.9362 - precision: 0.7073 - recall: 0.3278 - false_negatives: 1868.0000 - false_positives: 377.0000 - val_loss: 1.8737 - val_precision: 0.7905 - val_recall: 0.5270 - val_false_negatives: 105.0000 - val_false_positives: 31.0000\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 53s 1s/step - loss: 2.1714 - precision: 0.8224 - recall: 0.5118 - false_negatives: 994.0000 - false_positives: 225.0000 - val_loss: 1.7546 - val_precision: 0.8476 - val_recall: 0.6261 - val_false_negatives: 83.0000 - val_false_positives: 25.0000\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 53s 1s/step - loss: 1.8732 - precision: 0.8877 - recall: 0.5938 - false_negatives: 827.0000 - false_positives: 153.0000 - val_loss: 1.9625 - val_precision: 0.8854 - val_recall: 0.6261 - val_false_negatives: 83.0000 - val_false_positives: 18.0000\n",
            "19/19 [==============================] - 8s 417ms/step - loss: 2.1628 - precision: 0.8530 - recall: 0.6406 - false_negatives: 267.0000 - false_positives: 82.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnzcUlg_XQf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "561ecd83-5be6-4dd3-9937-130bb7dc7299"
      },
      "source": [
        "f1_score3 = 2 * (results3[1] * results3[2])/(results3[1] + results3[2])\n",
        "f1_score3"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7317448191407636"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9ZdtoFWYFKQ",
        "colab_type": "text"
      },
      "source": [
        "### With SGD Optimizer without Extra Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6hNSsq6Xlri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16c405f4-0832-48c0-8f99-aa645dd241fa"
      },
      "source": [
        "random.seed(123)\n",
        "# Three Inputs of the Bert Model\n",
        "InputIDLayer4 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"InputIDs\")\n",
        "MaskIDLayer4 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"MaskIDs\")\n",
        "SegmentIDLayer4 = Input(shape = (max_seq_length,), dtype = tf.int32, name = \"SegmentIDs\")\n",
        "\n",
        "# Import the pre-trained uncased Bert model\n",
        "bertLayer4 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=True)\n",
        "\n",
        "# Since it is a classisfication problem, the pooled output is needed.\n",
        "pooled_output4, sequence_output4 = bertLayer4([InputIDLayer4, MaskIDLayer4, SegmentIDLayer4])\n",
        "output4 = Dense(units = 12, activation = \"softmax\")(pooled_output4)\n",
        "\n",
        "model4 = Model(inputs=[InputIDLayer4, MaskIDLayer4, SegmentIDLayer4], outputs = output4)\n",
        "\n",
        "# Model Compilation\n",
        "learning_rate = 0.01\n",
        "number_of_epochs = 10\n",
        "optimizer4 = SGD(learning_rate = learning_rate)\n",
        "loss4 = CategoricalCrossentropy(from_logits = False)\n",
        "metrics4 = [Precision(), Recall(),\n",
        "          FalseNegatives(), FalsePositives()]\n",
        "\n",
        "model4.compile(optimizer = optimizer4, \n",
        "              loss = loss4,\n",
        "              metrics = metrics4)\n",
        "\n",
        "# Model Training & Fine-Tuning on train data\n",
        "earlyStopping4 = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 1)\n",
        "\n",
        "bert_history4 = model4.fit([input_ids, mask_ids, segments_ids], [multi_label],\n",
        "                         epochs = number_of_epochs, \n",
        "                         batch_size = 32,\n",
        "                         validation_split = 0.1,\n",
        "                         callbacks = [earlyStopping4]\n",
        "                         )\n",
        "# Model Evaluation - Loss, Precision, Recall, PrecisionAtRecall, RecallAtPrecision, FalseNegatives, FalsePositives\n",
        "results4 = model4.evaluate([input_ids_test, mask_ids_test, segments_ids_test], multi_label_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 55s 1s/step - loss: 2.2475 - precision: 0.8356 - recall: 0.4408 - false_negatives: 1554.0000 - false_positives: 241.0000 - val_loss: 1.7432 - val_precision: 0.8750 - val_recall: 0.5676 - val_false_negatives: 96.0000 - val_false_positives: 18.0000\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 53s 1s/step - loss: 1.7045 - precision: 0.8822 - recall: 0.5997 - false_negatives: 815.0000 - false_positives: 163.0000 - val_loss: 1.5465 - val_precision: 0.9073 - val_recall: 0.6171 - val_false_negatives: 85.0000 - val_false_positives: 14.0000\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 53s 1s/step - loss: 1.2953 - precision: 0.9544 - recall: 0.6783 - false_negatives: 655.0000 - false_positives: 66.0000 - val_loss: 1.6702 - val_precision: 0.8684 - val_recall: 0.5946 - val_false_negatives: 90.0000 - val_false_positives: 20.0000\n",
            "19/19 [==============================] - 8s 405ms/step - loss: 1.8433 - precision: 0.8548 - recall: 0.6258 - false_negatives: 278.0000 - false_positives: 79.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxqNGbYgYZep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03d42f0d-e652-4f18-f2fd-006c7b87ed58"
      },
      "source": [
        "f1_score4 = 2 * (results4[1] * results4[2])/(results4[1] + results4[2])\n",
        "f1_score4"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.722610737010602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}